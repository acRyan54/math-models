{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 距离判别法（多分类判别） sklearn.neighbors.KNeighborsClassifier\n",
    "\n",
    "> https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n",
    "\n",
    "优缺点：\n",
    "- **马氏距离**，它不受量纲的影响,两点之间的马氏距离与原始数据的测量单位无关；由标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同.马氏距离还可以排除变量之间的相关性的干扰.它的缺点是夸大了变化微小的变量的作用.\n",
    "\n",
    "- 欧氏距离，的优点简单有用，易于理解，缺点：它将样品的不同属性（即各指标或各变量）之间的差别等同看待,这一点有时不能满足实际要求.\n",
    "\n",
    "---\n",
    "\n",
    "- metric: 'minkowski'&p=2, 'euclidean', 'mahalanobis'马氏距离, 'seuclidean'数据标准化欧式距离\n",
    "- kneighbors(X=None, n_neighbors=None, return_distance=True) ：返回k近邻点的距离和下标\n",
    "\n",
    "\n",
    "KNN方法在类别决策时，只与极少量的相邻样本有关。由于KNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属类别的，因此**对于类域的交叉或重叠较多的待分样本集**来说，KNN方法较其他方法更为适合。\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "计算最近k个点的算法：kd-Tree\n",
    "https://zhuanlan.zhihu.com/p/393775739"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 1.]\n",
      "1.0\n",
      "(array([[0.47518672, 0.79137595],\n",
      "       [0.61718552, 0.66182395],\n",
      "       [0.71739148, 0.84641816]]), array([[11,  9],\n",
      "       [14, 11],\n",
      "       [ 4, 14]], dtype=int64))\n",
      "------------------------------\n",
      "[2. 1. 2.]\n",
      "1.0\n",
      "------------------------------\n",
      "(array([[0.47518672, 0.79137595],\n",
      "       [0.61718552, 0.66182395],\n",
      "       [0.71739148, 0.84641816]]), array([[11,  9],\n",
      "       [14, 11],\n",
      "       [ 4, 14]], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "np.set_printoptions(precision=8, suppress=True)\n",
    "\n",
    "X = np.array([[1.24,1.27], \n",
    "              [1.36,1.74], \n",
    "              [1.38,1.64], \n",
    "              [1.38,1.82], \n",
    "              [1.38,1.90], \n",
    "              [1.40,1.70],\n",
    "              [1.48,1.82], \n",
    "              [1.54,1.82], \n",
    "              [1.56,2.08],\n",
    "              [1.14,1.78], \n",
    "              [1.18,1.96], \n",
    "              [1.20,1.86],\n",
    "              [1.26,2.00], \n",
    "              [1.28,2.00], \n",
    "              [1.30,1.96]])\n",
    "y = np.hstack([np.ones(9), 2*np.ones(6)])\n",
    "X_test = np.array([[1.24,1.80], \n",
    "                   [1.28,1.84], \n",
    "                   [1.40,2.04]])\n",
    "\n",
    "cov_X = np.cov(X.T) # 协方差矩阵\n",
    "knn = KNeighborsClassifier(n_neighbors=2, metric='mahalanobis', metric_params={'V': cov_X}).fit(X,y) #马氏距离分类\n",
    "\n",
    "print(knn.predict(X_test))\n",
    "print(knn.score(X, y)) # 准确率\n",
    "print(knn.kneighbors(X_test, return_distance=True))\n",
    "# print(1 - knn.score(X, y)) # 误判率\n",
    "print('-'*30)\n",
    "\n",
    "knn1 = KNeighborsClassifier(n_neighbors=2).fit(X, y) # 欧氏距离分类\n",
    "\n",
    "print(knn1.predict(X_test))\n",
    "print(knn1.score(X, y)) # 准确率\n",
    "print('-'*30)\n",
    "\n",
    "print(knn.kneighbors(X_test, return_distance=True)) # 最近k个点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数选择\n",
    "\n",
    "- **网格搜索**\n",
    "- **交叉验证法**\n",
    "- 排序求出最好的参数\n",
    "\n",
    "> KNN中K值大小选择对模型的影响 - 黑马程序员的文章 - 知乎  https://zhuanlan.zhihu.com/p/526415029"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aa43cd2ccc1ff393b971fd4a3432410e7b10bb4b6c743baaacc4a3f13fd072bf"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
