{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn.preprocessing.PolynomialFeatures\n",
    "\n",
    "- **degree**: int or tuple (min_degree, max_degree), default=2\n",
    "\n",
    "\n",
    "- **interaction_only**: bool, default=False  是否仅含交叉项（次数至多为degree）\n",
    "\n",
    "\n",
    "- **include_bias**: bool, default=True 是否含常数项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "X = np.arange(6).reshape(3, 2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.],\n",
       "       [ 2.,  3.,  6.],\n",
       "       [ 4.,  5., 20.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(interaction_only=True, include_bias=False) # 只有交叉项 x0, x1, x0*x1\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 转换为多元线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 2. 1. 2. 4.]\n",
      " [2. 2. 4. 4. 4.]\n",
      " [2. 3. 4. 6. 9.]]\n",
      "------------------------------\n",
      "1.0\n",
      "3.6842105263157885 [ 0.18421053  1.78947368  0.55263158 -0.42105263  0.21052632]\n",
      "[17.10526316]\n"
     ]
    }
   ],
   "source": [
    "# 可以导入LinearRegression\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = np.array([[1, 1], \n",
    "              [1, 2], \n",
    "              [2, 2], \n",
    "              [2, 3]])\n",
    "# y = 3 + 1 * x_0 + 2 * x_1\n",
    "y = X @ np.array([1, 2]) + 3\n",
    "poly = PolynomialFeatures(2, include_bias=False)\n",
    "XX = poly.fit_transform(X)\n",
    "print(XX)\n",
    "print('-'*30)\n",
    "\n",
    "reg = LinearRegression().fit(XX, y)\n",
    "\n",
    "print(reg.score(XX, y))\n",
    "print(reg.intercept_, reg.coef_)\n",
    "\n",
    "print(reg.predict(poly.transform([[3, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 2. 1. 2. 4.]\n",
      " [1. 2. 2. 4. 4. 4.]\n",
      " [1. 2. 3. 4. 6. 9.]]\n",
      "------------------------------\n",
      "[ 2.59259259  1.68518519  1.92592593 -0.12962963 -0.14814815  0.07407407]\n",
      "                 Results: Ordinary least squares\n",
      "==================================================================\n",
      "Model:              OLS              Adj. R-squared:     nan      \n",
      "Dependent Variable: y                AIC:                -247.0090\n",
      "Date:               2022-08-26 22:43 BIC:                -249.4639\n",
      "No. Observations:   4                Log-Likelihood:     127.50   \n",
      "Df Model:           3                F-statistic:        nan      \n",
      "Df Residuals:       0                Prob (F-statistic): nan      \n",
      "R-squared:          1.000            Scale:              inf      \n",
      "---------------------------------------------------------------------\n",
      "           Coef.     Std.Err.       t       P>|t|    [0.025    0.975]\n",
      "---------------------------------------------------------------------\n",
      "const      2.5926         inf     0.0000      nan       nan       nan\n",
      "x1         1.6852         inf     0.0000      nan       nan       nan\n",
      "x2         1.9259         inf     0.0000      nan       nan       nan\n",
      "x3        -0.1296         inf    -0.0000      nan       nan       nan\n",
      "x4        -0.1481         inf    -0.0000      nan       nan       nan\n",
      "x5         0.0741         inf     0.0000      nan       nan       nan\n",
      "------------------------------------------------------------------\n",
      "Omnibus:               nan          Durbin-Watson:           0.213\n",
      "Prob(Omnibus):         nan          Jarque-Bera (JB):        0.419\n",
      "Skew:                  0.652        Prob(JB):                0.811\n",
      "Kurtosis:              2.097        Condition No.:           72   \n",
      "==================================================================\n",
      "\n",
      "[15.74074074]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\anaconda3\\lib\\site-packages\\statsmodels\\stats\\stattools.py:75: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n",
      "  \"samples were given.\" % int(n), ValueWarning)\n",
      "D:\\Softwares\\anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1671: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n",
      "D:\\Softwares\\anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1749: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "D:\\Softwares\\anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1750: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  * (1 - self.rsquared))\n"
     ]
    }
   ],
   "source": [
    "# 可以导入statsmodels\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X = np.array([[1, 1], \n",
    "              [1, 2], \n",
    "              [2, 2], \n",
    "              [2, 3]])\n",
    "# y = 3 + 1 * x_1 + 2 * x_2\n",
    "y = X @ np.array([1, 2]) + 3\n",
    "poly = PolynomialFeatures(2, include_bias=True)\n",
    "XX = poly.fit_transform(X)\n",
    "print(XX)\n",
    "print('-'*30)\n",
    "\n",
    "res = sm.OLS(y, XX).fit() # 自动从1开始给x编号\n",
    "print(res.params)\n",
    "print(res.summary2())\n",
    "# print(res.summary())\n",
    "\n",
    "print(res.predict(poly.transform([[3, 5]])))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aa43cd2ccc1ff393b971fd4a3432410e7b10bb4b6c743baaacc4a3f13fd072bf"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
